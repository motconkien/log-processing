[2025-06-29T00:00:24.690+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-06-29T00:00:24.897+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_log_processing.log_extraction scheduled__2025-06-28T00:00:00+00:00 [queued]>
[2025-06-29T00:00:24.902+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_log_processing.log_extraction scheduled__2025-06-28T00:00:00+00:00 [queued]>
[2025-06-29T00:00:24.903+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-06-29T00:00:24.911+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): log_extraction> on 2025-06-28 00:00:00+00:00
[2025-06-29T00:00:24.916+0000] {standard_task_runner.py:63} INFO - Started process 62 to run task
[2025-06-29T00:00:24.919+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'etl_log_processing', 'log_extraction', 'scheduled__2025-06-28T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/logs_dag.py', '--cfg-path', '/tmp/tmp3kbf89_z']
[2025-06-29T00:00:24.922+0000] {standard_task_runner.py:91} INFO - Job 6: Subtask log_extraction
[2025-06-29T00:00:24.965+0000] {task_command.py:426} INFO - Running <TaskInstance: etl_log_processing.log_extraction scheduled__2025-06-28T00:00:00+00:00 [running]> on host 71ba61a51b69
[2025-06-29T00:00:25.021+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Hoang' AIRFLOW_CTX_DAG_ID='etl_log_processing' AIRFLOW_CTX_TASK_ID='log_extraction' AIRFLOW_CTX_EXECUTION_DATE='2025-06-28T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-28T00:00:00+00:00'
[2025-06-29T00:00:25.022+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-06-29T00:00:25.031+0000] {logging_mixin.py:188} INFO - /opt/airflow/data//20250629_log.csv
[2025-06-29T00:00:26.038+0000] {logging_mixin.py:188} INFO -        event_id  ...                                     commit_message
0   51463263777  ...                                               None
1   51463263776  ...                                               None
2   51463263771  ...                       feat: added forecast command
3   51463263771  ...         Merge remote-tracking branch 'origin/main'
4   51463263775  ...                                               None
5   51463263761  ...                                               None
6   51463263759  ...                                      SajKuVwseGPmq
7   51463263773  ...                                               None
8   51463263767  ...                                               None
9   51463263763  ...                                               None
10  51463263726  ...                               Add files via upload
11  51463263755  ...                            commit from integ tests
12  51463263754  ...        Auto commit at Sat Jun 28 23:55:23 UTC 2025
13  51463263746  ...                           Writing file .prettierrc
14  51463263748  ...                                       theme colors
15  51463263753  ...  Auto update by GitHub Actions at Sun Jun 29 07...
16  51463263750  ...                                     rhFkpwfDxsiqBK
17  51463263743  ...         ðŸ¤– Auto Push Update 06/28/2025, 11:55:16 PM
18  51463263728  ...                                       Update Value
19  51463263732  ...         Auto-update data.json with latest readings
20  51463263733  ...                                               None
21  51463263723  ...                                  Updated gitignore
22  51463263721  ...                                               None
23  51463263718  ...                                               None
24  51463263751  ...                   Update Kindle weather/news image
25  51463263715  ...                                  Update index.html
26  51463263708  ...                        Updated plasma-pa - 6.4.1-1
27  51463263714  ...                               Update nosotros.html
28  51463263704  ...                                   NPYirwbKeTMDlIom
29  51463263702  ...                                                 ss
30  51463263698  ...                            Create README - LeetHub

[31 rows x 8 columns]
[2025-06-29T00:00:26.038+0000] {python.py:237} INFO - Done. Returned value was: /opt/airflow/data//20250629_log.csv
[2025-06-29T00:00:26.039+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-06-29T00:00:26.054+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=etl_log_processing, task_id=log_extraction, run_id=scheduled__2025-06-28T00:00:00+00:00, execution_date=20250628T000000, start_date=20250629T000024, end_date=20250629T000026
[2025-06-29T00:00:26.073+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-06-29T00:00:26.085+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-06-29T00:00:26.085+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-06-29T04:43:45.336+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-06-29T04:43:45.360+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_log_processing.log_extraction scheduled__2025-06-28T00:00:00+00:00 [queued]>
[2025-06-29T04:43:45.367+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_log_processing.log_extraction scheduled__2025-06-28T00:00:00+00:00 [queued]>
[2025-06-29T04:43:45.367+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-06-29T04:43:45.700+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): log_extraction> on 2025-06-28 00:00:00+00:00
[2025-06-29T04:43:45.718+0000] {standard_task_runner.py:63} INFO - Started process 53 to run task
[2025-06-29T04:43:45.729+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'etl_log_processing', 'log_extraction', 'scheduled__2025-06-28T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/logs_dag.py', '--cfg-path', '/tmp/tmp8gehyf9m']
[2025-06-29T04:43:45.739+0000] {standard_task_runner.py:91} INFO - Job 2: Subtask log_extraction
[2025-06-29T04:43:45.815+0000] {task_command.py:426} INFO - Running <TaskInstance: etl_log_processing.log_extraction scheduled__2025-06-28T00:00:00+00:00 [running]> on host 913c94ec1231
[2025-06-29T04:43:45.888+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Hoang' AIRFLOW_CTX_DAG_ID='etl_log_processing' AIRFLOW_CTX_TASK_ID='log_extraction' AIRFLOW_CTX_EXECUTION_DATE='2025-06-28T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-28T00:00:00+00:00'
[2025-06-29T04:43:45.889+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-06-29T04:43:45.924+0000] {logging_mixin.py:188} INFO - /opt/airflow/data/logs/data/logs/20250629_log.csv
[2025-06-29T04:43:46.649+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-06-29T04:43:46.650+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/pipelines/log_pipeline.py", line 15, in log_pipeline
    load_file(df,file_path)
  File "/opt/airflow/etls/log_etl.py", line 72, in load_file
    df.to_csv(file_path, index = False)
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/generic.py", line 3902, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/io/formats/format.py", line 1152, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/io/formats/csvs.py", line 247, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/io/common.py", line 739, in get_handle
    check_parent_directory(str(handle))
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/io/common.py", line 604, in check_parent_directory
    raise OSError(rf"Cannot save file into a non-existent directory: '{parent}'")
OSError: Cannot save file into a non-existent directory: '/opt/airflow/data/logs/data/logs'
[2025-06-29T04:43:46.671+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=etl_log_processing, task_id=log_extraction, run_id=scheduled__2025-06-28T00:00:00+00:00, execution_date=20250628T000000, start_date=20250629T044345, end_date=20250629T044346
[2025-06-29T04:43:46.684+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 2 for task log_extraction (Cannot save file into a non-existent directory: '/opt/airflow/data/logs/data/logs'; 53)
[2025-06-29T04:43:46.705+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-06-29T04:43:46.732+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-06-29T04:43:46.737+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
